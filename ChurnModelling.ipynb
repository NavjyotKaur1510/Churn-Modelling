{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p2WVdExFPS32"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    0\n",
              "4    0\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THU95YqmSRz6",
        "outputId": "e69769b3-ca65-4026-8b50-41c41f2d4daf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rdnyqzxAR3OG"
      },
      "outputs": [],
      "source": [
        "geography= pd.get_dummies(x[\"Geography\"], drop_first= True)  #get dummies is used to make columns of all the possible choices of the selected column from the dataset\n",
        "gender= pd.get_dummies(x[\"Gender\"], drop_first=True)   # dropfirst is used to delete the first column, minimize data redundancy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEHcvNKcSYV0",
        "outputId": "3c67f30f-e6d6-4ca1-b0ad-cfee583d54c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Germany  Spain\n",
            "0       False  False\n",
            "1       False   True\n",
            "2       False  False\n",
            "3       False  False\n",
            "4       False   True\n",
            "...       ...    ...\n",
            "9995    False  False\n",
            "9996    False  False\n",
            "9997    False  False\n",
            "9998     True  False\n",
            "9999    False  False\n",
            "\n",
            "[10000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(geography)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl5IHXkUSgdp",
        "outputId": "813a886c-f872-4c53-ce51-2e8b50ea6ffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "print(type(geography))     #will come out as a dataframe only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LhcJ9UCcSkVu"
      },
      "outputs": [],
      "source": [
        "x= pd.concat([x,gender, geography], axis=1)   #concat the newly made dataframe\n",
        "x=x.drop([\"Geography\", \"Gender\"], axis=1)   # delete the old ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "F-DhFH6HTd-s"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JnWURQIOTDvn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler   #used to minimize the difference b/w 2 extrame numerical values\n",
        "sc= StandardScaler()\n",
        "x_train= sc.fit_transform(x_train)\n",
        "x_test= sc.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zpTG5u5BTDx2"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential    \u001b[38;5;66;03m#responsible fro creating the neural network\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense         \u001b[38;5;66;03m#to create the hidden layers\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential    #responsible fro creating the neural network\n",
        "from keras.layers import Dense         #to create the hidden layers\n",
        "from keras.layers import LeakyReLU, PReLU, ELU\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbHQHRPtTD1P",
        "outputId": "d437d5f0-3229-428e-8b14-80615b0cc460"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "classifier= Sequential()      #create an empty neural network\n",
        "classifier.add(Dense(units=6, kernel_initializer= \"he_uniform\", activation= \"relu\", input_dim=11))   #creating the first hidden layer, units=no of neurons, kernel= weight initializer, input_dim= no of inputs\n",
        "classifier.add(Dense(units=6, kernel_initializer= \"he_uniform\", activation= \"relu\"))\n",
        "classifier.add(Dense(units=1, kernel_initializer= \"glorot_uniform\", activation= \"sigmoid\"))          #only one hidden neurom as binary clasification\n",
        "classifier.compile(optimizer= \"adamax\", loss= \"binary_crossentropy\", metrics= [\"accuracy\"])          #when o/p either 0 or 1 we use binary cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcT1uFUPXn56",
        "outputId": "61f3fc86-66de-4474-e95c-605bbc89f061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6309 - loss: 0.6974 - val_accuracy: 0.7384 - val_loss: 0.5881\n",
            "Epoch 2/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.5546 - val_accuracy: 0.7861 - val_loss: 0.5338\n",
            "Epoch 3/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7950 - loss: 0.5128 - val_accuracy: 0.7963 - val_loss: 0.5083\n",
            "Epoch 4/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.4859 - val_accuracy: 0.8001 - val_loss: 0.4930\n",
            "Epoch 5/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8154 - loss: 0.4695 - val_accuracy: 0.7997 - val_loss: 0.4830\n",
            "Epoch 6/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.4517 - val_accuracy: 0.8012 - val_loss: 0.4759\n",
            "Epoch 7/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.4526 - val_accuracy: 0.8005 - val_loss: 0.4716\n",
            "Epoch 8/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.4508 - val_accuracy: 0.8001 - val_loss: 0.4680\n",
            "Epoch 9/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8113 - loss: 0.4549 - val_accuracy: 0.8031 - val_loss: 0.4658\n",
            "Epoch 10/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8070 - loss: 0.4593 - val_accuracy: 0.8039 - val_loss: 0.4635\n",
            "Epoch 11/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4471 - val_accuracy: 0.8027 - val_loss: 0.4619\n",
            "Epoch 12/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.4442 - val_accuracy: 0.8023 - val_loss: 0.4597\n",
            "Epoch 13/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.4474 - val_accuracy: 0.8023 - val_loss: 0.4579\n",
            "Epoch 14/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8147 - loss: 0.4446 - val_accuracy: 0.8035 - val_loss: 0.4559\n",
            "Epoch 15/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.4433 - val_accuracy: 0.8042 - val_loss: 0.4543\n",
            "Epoch 16/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8257 - loss: 0.4290 - val_accuracy: 0.8042 - val_loss: 0.4524\n",
            "Epoch 17/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8174 - loss: 0.4348 - val_accuracy: 0.8035 - val_loss: 0.4510\n",
            "Epoch 18/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8268 - loss: 0.4236 - val_accuracy: 0.8058 - val_loss: 0.4498\n",
            "Epoch 19/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.4294 - val_accuracy: 0.8058 - val_loss: 0.4478\n",
            "Epoch 20/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8214 - loss: 0.4303 - val_accuracy: 0.8061 - val_loss: 0.4467\n",
            "Epoch 21/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8251 - loss: 0.4243 - val_accuracy: 0.8058 - val_loss: 0.4456\n",
            "Epoch 22/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4444 - val_accuracy: 0.8046 - val_loss: 0.4443\n",
            "Epoch 23/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8288 - loss: 0.4112 - val_accuracy: 0.8065 - val_loss: 0.4435\n",
            "Epoch 24/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4262 - val_accuracy: 0.8061 - val_loss: 0.4418\n",
            "Epoch 25/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4104 - val_accuracy: 0.8065 - val_loss: 0.4408\n",
            "Epoch 26/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.4188 - val_accuracy: 0.8080 - val_loss: 0.4391\n",
            "Epoch 27/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4130 - val_accuracy: 0.8092 - val_loss: 0.4376\n",
            "Epoch 28/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.4149 - val_accuracy: 0.8111 - val_loss: 0.4362\n",
            "Epoch 29/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8326 - loss: 0.4005 - val_accuracy: 0.8107 - val_loss: 0.4348\n",
            "Epoch 30/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.4186 - val_accuracy: 0.8129 - val_loss: 0.4325\n",
            "Epoch 31/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8272 - loss: 0.4144 - val_accuracy: 0.8126 - val_loss: 0.4303\n",
            "Epoch 32/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8233 - loss: 0.4111 - val_accuracy: 0.8141 - val_loss: 0.4279\n",
            "Epoch 33/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.4014 - val_accuracy: 0.8152 - val_loss: 0.4255\n",
            "Epoch 34/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8253 - loss: 0.4084 - val_accuracy: 0.8167 - val_loss: 0.4232\n",
            "Epoch 35/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.4004 - val_accuracy: 0.8167 - val_loss: 0.4201\n",
            "Epoch 36/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8366 - loss: 0.3873 - val_accuracy: 0.8201 - val_loss: 0.4174\n",
            "Epoch 37/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8325 - loss: 0.3980 - val_accuracy: 0.8209 - val_loss: 0.4145\n",
            "Epoch 38/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8365 - loss: 0.3934 - val_accuracy: 0.8224 - val_loss: 0.4116\n",
            "Epoch 39/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8303 - loss: 0.3953 - val_accuracy: 0.8236 - val_loss: 0.4093\n",
            "Epoch 40/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.3864 - val_accuracy: 0.8254 - val_loss: 0.4067\n",
            "Epoch 41/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8353 - loss: 0.3854 - val_accuracy: 0.8251 - val_loss: 0.4040\n",
            "Epoch 42/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.3657 - val_accuracy: 0.8258 - val_loss: 0.4014\n",
            "Epoch 43/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8461 - loss: 0.3669 - val_accuracy: 0.8262 - val_loss: 0.3988\n",
            "Epoch 44/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8493 - loss: 0.3783 - val_accuracy: 0.8277 - val_loss: 0.3963\n",
            "Epoch 45/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8481 - loss: 0.3747 - val_accuracy: 0.8289 - val_loss: 0.3942\n",
            "Epoch 46/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.3648 - val_accuracy: 0.8296 - val_loss: 0.3920\n",
            "Epoch 47/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.3613 - val_accuracy: 0.8315 - val_loss: 0.3900\n",
            "Epoch 48/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.3580 - val_accuracy: 0.8300 - val_loss: 0.3884\n",
            "Epoch 49/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.3600 - val_accuracy: 0.8304 - val_loss: 0.3866\n",
            "Epoch 50/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8527 - loss: 0.3606 - val_accuracy: 0.8330 - val_loss: 0.3851\n",
            "Epoch 51/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.3457 - val_accuracy: 0.8338 - val_loss: 0.3835\n",
            "Epoch 52/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3414 - val_accuracy: 0.8368 - val_loss: 0.3816\n",
            "Epoch 53/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3565 - val_accuracy: 0.8383 - val_loss: 0.3802\n",
            "Epoch 54/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8500 - loss: 0.3619 - val_accuracy: 0.8383 - val_loss: 0.3787\n",
            "Epoch 55/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.3346 - val_accuracy: 0.8398 - val_loss: 0.3777\n",
            "Epoch 56/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8582 - loss: 0.3468 - val_accuracy: 0.8406 - val_loss: 0.3769\n",
            "Epoch 57/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.3568 - val_accuracy: 0.8436 - val_loss: 0.3763\n",
            "Epoch 58/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3452 - val_accuracy: 0.8429 - val_loss: 0.3757\n",
            "Epoch 59/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 0.3409 - val_accuracy: 0.8429 - val_loss: 0.3749\n",
            "Epoch 60/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8592 - loss: 0.3455 - val_accuracy: 0.8448 - val_loss: 0.3743\n",
            "Epoch 61/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.3461 - val_accuracy: 0.8455 - val_loss: 0.3738\n",
            "Epoch 62/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8547 - loss: 0.3371 - val_accuracy: 0.8451 - val_loss: 0.3733\n",
            "Epoch 63/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.3391 - val_accuracy: 0.8463 - val_loss: 0.3730\n",
            "Epoch 64/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.3349 - val_accuracy: 0.8463 - val_loss: 0.3725\n",
            "Epoch 65/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8586 - loss: 0.3413 - val_accuracy: 0.8466 - val_loss: 0.3725\n",
            "Epoch 66/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.3437 - val_accuracy: 0.8474 - val_loss: 0.3721\n",
            "Epoch 67/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3554 - val_accuracy: 0.8474 - val_loss: 0.3718\n",
            "Epoch 68/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8533 - loss: 0.3594 - val_accuracy: 0.8459 - val_loss: 0.3716\n",
            "Epoch 69/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3451 - val_accuracy: 0.8474 - val_loss: 0.3714\n",
            "Epoch 70/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3378 - val_accuracy: 0.8478 - val_loss: 0.3711\n",
            "Epoch 71/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3460 - val_accuracy: 0.8489 - val_loss: 0.3709\n",
            "Epoch 72/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.3291 - val_accuracy: 0.8478 - val_loss: 0.3709\n",
            "Epoch 73/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8555 - loss: 0.3471 - val_accuracy: 0.8497 - val_loss: 0.3706\n",
            "Epoch 74/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3516 - val_accuracy: 0.8459 - val_loss: 0.3704\n",
            "Epoch 75/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3201 - val_accuracy: 0.8485 - val_loss: 0.3704\n",
            "Epoch 76/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8590 - loss: 0.3417 - val_accuracy: 0.8485 - val_loss: 0.3701\n",
            "Epoch 77/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3283 - val_accuracy: 0.8482 - val_loss: 0.3699\n",
            "Epoch 78/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.3447 - val_accuracy: 0.8474 - val_loss: 0.3699\n",
            "Epoch 79/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.3446 - val_accuracy: 0.8463 - val_loss: 0.3697\n",
            "Epoch 80/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3436 - val_accuracy: 0.8482 - val_loss: 0.3696\n",
            "Epoch 81/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.3427 - val_accuracy: 0.8489 - val_loss: 0.3697\n",
            "Epoch 82/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8521 - loss: 0.3390 - val_accuracy: 0.8493 - val_loss: 0.3696\n",
            "Epoch 83/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.3416 - val_accuracy: 0.8478 - val_loss: 0.3695\n",
            "Epoch 84/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.3311 - val_accuracy: 0.8482 - val_loss: 0.3695\n",
            "Epoch 85/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8593 - loss: 0.3416 - val_accuracy: 0.8485 - val_loss: 0.3693\n",
            "Epoch 86/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8560 - loss: 0.3369 - val_accuracy: 0.8485 - val_loss: 0.3690\n",
            "Epoch 87/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3453 - val_accuracy: 0.8474 - val_loss: 0.3690\n",
            "Epoch 88/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8626 - loss: 0.3373 - val_accuracy: 0.8493 - val_loss: 0.3690\n",
            "Epoch 89/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8583 - loss: 0.3400 - val_accuracy: 0.8478 - val_loss: 0.3688\n",
            "Epoch 90/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8531 - loss: 0.3532 - val_accuracy: 0.8463 - val_loss: 0.3686\n",
            "Epoch 91/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.3461 - val_accuracy: 0.8470 - val_loss: 0.3686\n",
            "Epoch 92/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3333 - val_accuracy: 0.8485 - val_loss: 0.3687\n",
            "Epoch 93/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.3379 - val_accuracy: 0.8474 - val_loss: 0.3684\n",
            "Epoch 94/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.3403 - val_accuracy: 0.8478 - val_loss: 0.3683\n",
            "Epoch 95/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.3317 - val_accuracy: 0.8470 - val_loss: 0.3683\n",
            "Epoch 96/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3375 - val_accuracy: 0.8466 - val_loss: 0.3681\n",
            "Epoch 97/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8582 - loss: 0.3427 - val_accuracy: 0.8474 - val_loss: 0.3681\n",
            "Epoch 98/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8536 - loss: 0.3505 - val_accuracy: 0.8466 - val_loss: 0.3678\n",
            "Epoch 99/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3358 - val_accuracy: 0.8474 - val_loss: 0.3679\n",
            "Epoch 100/100\n",
            "\u001b[1m536/536\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3261 - val_accuracy: 0.8474 - val_loss: 0.3680\n"
          ]
        }
      ],
      "source": [
        "model_history= classifier.fit(x_train, y_train, validation_split=0.33, batch_size=10, epochs=100)   #batch_size= no of batches, if overfitting- reduce epochs and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkO4iwvhXn9c",
        "outputId": "cee2c6c4-5816-4e4b-fa44-fc67fcd1eff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
          ]
        }
      ],
      "source": [
        "ypred= classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOMMjH1ZZpGJ",
        "outputId": "291bef41-90d1-4dbd-f71b-89c1e5f38aa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.3711434 ]\n",
            " [0.45100462]\n",
            " [0.19549192]\n",
            " ...\n",
            " [0.1707028 ]\n",
            " [0.2072838 ]\n",
            " [0.27946767]]\n"
          ]
        }
      ],
      "source": [
        "print(ypred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtRAvex7ZugC"
      },
      "outputs": [],
      "source": [
        "ypred=(ypred>0.5)    #gives false if condition(ypred>0.5) not true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iql0dTf3ZzlE",
        "outputId": "b9ad82e5-4fb7-49e6-c11e-7eeeaeb8768b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " ...\n",
            " [False]\n",
            " [False]\n",
            " [False]]\n"
          ]
        }
      ],
      "source": [
        "print(ypred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5fOVdE9Z1Aq",
        "outputId": "e76f9b77-bb47-4ab5-c65a-4670acddd553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.861\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "score= accuracy_score(y_test, ypred)      #y_test= actual values, ypred= predicted values\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQNkYponaYKC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3bYLveTbLg4"
      },
      "source": [
        "Parameters: Something that model learns during the machine learning process.\n",
        "\n",
        "Example: Weights, Bias etc.\n",
        "\n",
        "HyperParameters: Something that is manually specified.\n",
        "\n",
        "Example: Learning rate, Number of epochs, Number of layers, Number of neurons in each layer.\n",
        "\n",
        "Biases are the parameters which allow the model to shift the activation function and outputs, enabling the model to fit better on the data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
